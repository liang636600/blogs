# 1 

![image-20211120144320077](https://raw.githubusercontent.com/liang636600/cloudImg/master/images/image-20211120144320077.png)

2>&1的解释：

0 stdin，1 stdout，2 stderr

2>&1应该分成两个部分来看，一个是2>以及另一个是&1，其中2>就是将标准出错重定向到某个特定的地方；&1是指无论标准输出在哪里。所以2>&1的意思就是说无论标准出错在哪里，都将标准出错重定向到标准输出中

tee从标准输入中读取，并将读入的内容写到标准输出以及文件中，这里$7应该是log文件

# 2

doCommand.sh文件是Linux批量创建主机信任关系

# 3 尝试运行一个sample

## 3.1 首先打包源码为一个jar包

使用sbt打包

---


报错`object SparkSession is not a member of package org.apache.spark.sql`

* 尝试修改simple.sbt在末尾加上一行`libraryDependencies += "org.apache.spark" %% "spark-sql" % "3.2.0"`

---

报错`LogisticRegressionWithSGDTest.scala:4:25: object mllib is not a member of package org.apache.spark`

* 尝试在simple.sbt的末尾加上一行`libraryDependencies += "org.apache.spark" %% "spark-mllib" % "3.2.0"`

---

报错`LogisticRegressionWithSGDTest.scala:28:17: not found: value LogisticRegressionWithSGD`

* 尝试删除LogisticRegressionWithSGDTest文件

---

## 3.2 运行shell脚本

提示权限不够`bash: ./GroupByRDD-sample.sh: 权限不够`

* 尝试`chmod 777 ./GroupByRDD-sample.sh`再运行

---

运行报错`JAVA_HOME is not set`

* 因为这里是root在运行，所以短期解决方案是直接加上`export JAVA_HOME=/home/iscas/Downloads/openjdk-16_linux-x64_bin/jdk-16`

---

运行成功生成一个RDDGroupByTest文件夹

![image-20211120164905120](https://raw.githubusercontent.com/liang636600/cloudImg/master/images/image-20211120164905120.png)

# 4 尝试使用ZGC运行

修改参数为使用ZGC `"-XX:+UseZGC`

运行也成功
