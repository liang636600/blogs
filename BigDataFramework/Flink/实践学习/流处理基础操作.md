# 1 DataStream的基本概念

## WordCount实例

```JAVA

import org.apache.flink.api.common.functions.FlatMapFunction;
import org.apache.flink.api.common.typeinfo.Types;
import org.apache.flink.api.java.tuple.Tuple2;
import org.apache.flink.streaming.api.datastream.SingleOutputStreamOperator;
import org.apache.flink.streaming.api.environment.StreamExecutionEnvironment;
import org.apache.flink.streaming.api.datastream.DataStream;
import org.apache.flink.api.common.functions.FilterFunction;
import org.apache.flink.util.Collector;

public class StreamingJob {
    public static final String[] WORDS = new String[]{
            "com.intsmaze.flink.streaming.window.helloword.WordCountTemplate",
            "com.intsmaze.flink.streaming.window.helloword.WordCountTemplate",
            "com.intsmaze.flink.streaming.window.helloword.WordCountTemplate",
            "com.intsmaze.flink.streaming.window.helloword.WordCountTemplate",
    };

    public static void main(String[] args) throws Exception {
        final StreamExecutionEnvironment env = StreamExecutionEnvironment.getExecutionEnvironment();
        DataStream<String> text = env.fromElements(WORDS);
        DataStream<Tuple2<String, Integer>> word = text.flatMap(new FlatMapFunction<String, Tuple2<String, Integer>>() {
            // 对于text中的每一条记录，使用map方法，即先把String split后，加入到集合out中去，out的结果为word变量
            @Override
            public void flatMap(String value, Collector<Tuple2<String, Integer>> out) throws Exception {
                String[] tokens = value.toLowerCase().split("\\.");
                for (String token : tokens) {
                    if (token.length() > 0) {
                        out.collect(new Tuple2<>(token, 1));
                    }
                }
            }
        });
        DataStream<Tuple2<String, Integer>> counts = word.keyBy("f0").sum(1);
        counts.print("hello dataStream");
        env.execute();
    }


}
```

## 数据源

如果Flink内置的数据源函数不满足开发者需求，通过为非并行数据源实现SourceFunction接口或为并行数据源实现ParallelSourceFunction接口或扩展RichParallelSourceFunction抽象类来编写自己的定制数据源

### 基于文件

![1654052373749](https://raw.githubusercontent.com/liang636600/cloudImg/master/images/1654052373749.jpg)

![1654052395686](https://raw.githubusercontent.com/liang636600/cloudImg/master/images/1654052395686.jpg)

![1654052703970](https://raw.githubusercontent.com/liang636600/cloudImg/master/images/1654052703970.jpg)

![1654052728656](https://raw.githubusercontent.com/liang636600/cloudImg/master/images/1654052728656.jpg)

* 实例1，直接使用readTextFile读取文件

  创建文件a.txt内容如下

  ```
  hello world
  what a good day
  there is 
  ```

  ```JAVA
  final StreamExecutionEnvironment env = StreamExecutionEnvironment.getExecutionEnvironment();
          DataStreamSource<String> stringDataStreamSource = env.readTextFile("///home/driverliang/a.txt");
          stringDataStreamSource.print();
          env.execute();
  ```

* 实例2，使用readFile监控读取文件

  每隔一段时间扫描文件，当文件改变时重新读取文件所有内容处理

  ```JAVA
  final StreamExecutionEnvironment env = StreamExecutionEnvironment.getExecutionEnvironment();
  
  String filePath = "///home/driverliang/files";
  TextInputFormat format = new TextInputFormat(new Path(filePath));
  TypeInformation<String> typeInfo = BasicTypeInfo.STRING_TYPE_INFO;
  DataStream<String> dataStream = env.readFile(format, filePath,
                                               FileProcessingMode.PROCESS_CONTINUOUSLY, 5000, typeInfo);
  
  dataStream.print();
  env.execute();
  ```

### 基于Socket

![1654055970940](https://raw.githubusercontent.com/liang636600/cloudImg/master/images/1654055970940.jpg)

### 基于集合

![1654056233799](https://raw.githubusercontent.com/liang636600/cloudImg/master/images/1654056233799.jpg)

### 自定义数据源函数

![1654056447642](https://raw.githubusercontent.com/liang636600/cloudImg/master/images/1654056447642.jpg)

## 数据接收器（数据保存）Sink

### 基于文件

![1654056665702](https://raw.githubusercontent.com/liang636600/cloudImg/master/images/1654056665702.jpg)

![1654056813232](https://raw.githubusercontent.com/liang636600/cloudImg/master/images/1654056813232.jpg)

### 基于标准输出流

![1654057115886](https://raw.githubusercontent.com/liang636600/cloudImg/master/images/1654057115886.jpg)

### 基于Socket

![1654057246171](https://raw.githubusercontent.com/liang636600/cloudImg/master/images/1654057246171.jpg)

### 自定义数据接收器函数

![1654057593851](https://raw.githubusercontent.com/liang636600/cloudImg/master/images/1654057593851.jpg)

# 2 数据流基本操作

## Map

```JAVA
        final StreamExecutionEnvironment env = StreamExecutionEnvironment.getExecutionEnvironment();
        DataStream<Long> streamSource = env.generateSequence(1, 5);

        DataStream<Tuple2<Long, Integer>> mapStream = streamSource
                .map(new MapFunction<Long, Tuple2<Long, Integer>>() {
                    @Override
                    public Tuple2<Long, Integer> map(Long values) {
                        return new Tuple2<>(values * 100, values.hashCode());
                    }
                });
        mapStream.print("输出结果");
        env.execute();
```

## FlatMap

数据流中的每个元素将作为输入元素进入FlatMapFunction函数，FlatMapFunction函数将对输入的元素进行转换并产生0个，1个或多个结果元素输出到新的数据流中，典型应用场景是拆分不需要的列表和数组

```java
StreamExecutionEnvironment env = StreamExecutionEnvironment.getExecutionEnvironment();

        DataStream<Tuple2<String, Integer>> streamSource = env.fromElements(
                new Tuple2<>("liu yang", 1),
                new Tuple2<>("my blog is intsmaze", 2),
                new Tuple2<>("hello flink", 2));

        DataStream<Tuple1<String>> resultStream = streamSource
                .flatMap(new FlatMapFunction<Tuple2<String, Integer>, Tuple1<String>>() {
                    @Override
                    public void flatMap(Tuple2<String, Integer> value,
                                        Collector<Tuple1<String>> out) {

                        if ("liu yang".equals(value.f0)) {
                            return;
                        } else if (value.f0.indexOf("intsmaze") >= 0) {
                            for (String word : value.f0.split(" ")) {
                                out.collect(Tuple1.of("Split intsmaze：" + word));
                            }
                        } else {
                            out.collect(Tuple1.of("Not included intsmaze：" + value.f0));
                        }
                    }
                });
        resultStream.print("输出结果");

        env.execute("FlatMapTemplate");
```

## Filter

返回true表示保留该元素，典型应用场景是数据去重

```JAVA
StreamExecutionEnvironment env = StreamExecutionEnvironment.getExecutionEnvironment();
        DataStream<Long> streamSource = env.generateSequence(1, 5);
        DataStream<Long> filterStream = streamSource.filter(new FilterFunction<Long>() {
            @Override
            public boolean filter(Long value) throws Exception {
                if (value == 2L || value == 4L) {
                    return false;
                }
                return true;
            }
        });
        filterStream.print("输出结果");
        env.execute("Filter Template");
```

## KeyBy

具有相同key的元素print操作符的同一个子任务中进行处理

实现DataStream -> KeyedStream转换

```JAVA
StreamExecutionEnvironment env = StreamExecutionEnvironment.getExecutionEnvironment();
        env.setParallelism(10);
        List<Tuple2<Integer, Integer>> list = new ArrayList<Tuple2<Integer, Integer>>();
        list.add(new Tuple2<>(1, 11));
        list.add(new Tuple2<>(1, 22));
        list.add(new Tuple2<>(3, 33));
        list.add(new Tuple2<>(5, 55));

        DataStream<Tuple2<Integer, Integer>> dataStream = env.fromCollection(list);

        KeyedStream<Tuple2<Integer, Integer>, Tuple> keyedStream = dataStream.keyBy(0);

        keyedStream.print("输出结果");

        env.execute("KeyByTemplate");
```

## Reduce

实现KeyedStream -> DataStream 转换

```JAVA
        StreamExecutionEnvironment env = StreamExecutionEnvironment.getExecutionEnvironment();

        List<Tuple3<Tuple2<Integer, String>, Integer, Integer>> list = new ArrayList<Tuple3<Tuple2<Integer, String>, Integer, Integer>>();
        list.add(new Tuple3(new Tuple2(1, "intsmaze"), 1, 11));
        list.add(new Tuple3(new Tuple2(1, "intsmaze"), 1, 22));
        list.add(new Tuple3(new Tuple2(33, "liuyang"), 33, 333));

        DataStream<Tuple3<Tuple2<Integer, String>, Integer, Integer>> dataStream = env
                .fromCollection(list)
                .keyBy("f0.f1")
                .reduce(new ReduceFunction<Tuple3<Tuple2<Integer, String>, Integer, Integer>>() {
                    @Override
                    public Tuple3<Tuple2<Integer, String>, Integer, Integer> reduce(
                            Tuple3<Tuple2<Integer, String>, Integer, Integer> value1,
                            Tuple3<Tuple2<Integer, String>, Integer, Integer> value2) {
                        Tuple2 tuple2 = value1.getField(0);
                        int v1 = value1.getField(1);
                        int v2 = value2.getField(1);
                        int v3 = value1.getField(2);
                        int v4 = value2.getField(2);
                        return new Tuple3(tuple2, v1 + v2, v3 + v4);
                    }
                });
        dataStream.print();
        env.execute("KeyByTemplate");
```

## Aggregations



