![image-20220605090341200](https://raw.githubusercontent.com/liang636600/cloudImg/master/images/image-20220605090341200.png)

# 1 牛顿法

## 应用：求方程的近似解

![image-20220603203505582](https://raw.githubusercontent.com/liang636600/cloudImg/master/images/image-20220603203505582.png)

计算f(x)=0的解
$$
x_{k+1}=x_{k}-\frac{f(x_{k})}{{f}'(x_{k})}
$$
选择一个初始值x0，根据上面公式迭代获得x1，一直迭代，直到满足精度（例如abs( x(n+1)-xn)<ε ）或达到最大迭代次数

## 原理

### 一元函数

![image-20220604174609634](https://raw.githubusercontent.com/liang636600/cloudImg/master/images/image-20220604174609634.png)

![image-20220604174733684](https://raw.githubusercontent.com/liang636600/cloudImg/master/images/image-20220604174733684.png)

代码实现

![image-20220604174943282](https://raw.githubusercontent.com/liang636600/cloudImg/master/images/image-20220604174943282.png)

![image-20220604175134463](https://raw.githubusercontent.com/liang636600/cloudImg/master/images/image-20220604175134463.png)

**使用条件：**起始点足够接近极小点

对于凸函数而言

![image-20220603205539182](https://raw.githubusercontent.com/liang636600/cloudImg/master/images/image-20220603205539182.png)

### 多元函数

![image-20220604213954223](https://raw.githubusercontent.com/liang636600/cloudImg/master/images/image-20220604213954223.png)

![image-20220604214824376](https://raw.githubusercontent.com/liang636600/cloudImg/master/images/image-20220604214824376.png)

代码

fd表示梯度函数

![image-20220604215217519](https://raw.githubusercontent.com/liang636600/cloudImg/master/images/image-20220604215217519.png)

![image-20220604215127792](https://raw.githubusercontent.com/liang636600/cloudImg/master/images/image-20220604215127792.png)

### 缺点

![image-20220604215338793](https://raw.githubusercontent.com/liang636600/cloudImg/master/images/image-20220604215338793.png)

![image-20220604215827046](https://raw.githubusercontent.com/liang636600/cloudImg/master/images/image-20220604215827046.png)

## 应用：求凸函数的极小值

![image-20220603210753718](https://raw.githubusercontent.com/liang636600/cloudImg/master/images/image-20220603210753718.png)

# 2 割线法

差分近似微分，即
$$
{f}''(a_{k})=\frac{{f}'(a_{k})-{f}'(a_{k-1})}{a_{k}-a_{k-1}}
$$
然后迭代的式子变为下面

![image-20220604175924319](https://raw.githubusercontent.com/liang636600/cloudImg/master/images/image-20220604175924319.png)

代码实现

下面代码中l表示的是ak，u表示的是ak-1

初始值ak-1为1.1*（ak）

![image-20220604180115281](https://raw.githubusercontent.com/liang636600/cloudImg/master/images/image-20220604180115281.png)

# 3 修正牛顿法（Levenberg-Marquardt）

存在计算量巨大的缺点

## 解决不能保证目标函数值下降问题

加入了学习率α

![image-20220604221350403](https://raw.githubusercontent.com/liang636600/cloudImg/master/images/image-20220604221350403.png)

其中α值的确定

![image-20220604221508138](https://raw.githubusercontent.com/liang636600/cloudImg/master/images/image-20220604221508138.png)

搜索更新的代码



![image-20220604221547728](https://raw.githubusercontent.com/liang636600/cloudImg/master/images/image-20220604221547728.png)

## 解决非正定黑塞矩阵问题

![image-20220604222117494](https://raw.githubusercontent.com/liang636600/cloudImg/master/images/image-20220604222117494.png)

代码，其中eigmin表示求最小特征值

![image-20220604222221339](https://raw.githubusercontent.com/liang636600/cloudImg/master/images/image-20220604222221339.png)

![image-20220604222351747](https://raw.githubusercontent.com/liang636600/cloudImg/master/images/image-20220604222351747.png)

# 4 高斯牛顿法

已知模型的表达式，但模型中有一些参数未知，通过部分点确定这些未知参数的值

![image-20220608193653946](https://raw.githubusercontent.com/liang636600/cloudImg/master/images/image-20220608193653946.png)

![image-20220608194034679](https://raw.githubusercontent.com/liang636600/cloudImg/master/images/image-20220608194034679.png)

![image-20220608194122162](https://raw.githubusercontent.com/liang636600/cloudImg/master/images/image-20220608194122162.png)

![1654688768259](https://raw.githubusercontent.com/liang636600/cloudImg/master/images/1654688768259.jpg)

![image-20220608194830230](https://raw.githubusercontent.com/liang636600/cloudImg/master/images/image-20220608194830230.png)

![image-20220608195647280](https://raw.githubusercontent.com/liang636600/cloudImg/master/images/image-20220608195647280.png)

![image-20220608195833585](https://raw.githubusercontent.com/liang636600/cloudImg/master/images/image-20220608195833585.png)

因为ri在模型较好的情况下一般为0，所以忽略O矩阵

![image-20220608200157527](https://raw.githubusercontent.com/liang636600/cloudImg/master/images/image-20220608200157527.png)

**代码**

f(x,a,b)表示模型，例如f=a+b*x^2(这里a，b表示参数)

g(x,a,b)是针对参数（β）求得的梯度（上面f中对应的是[1,x^2]），而不是对变量

data是数据，矩阵，一行表示一个观测点[x11,x12,x13...y1]

start表示参数的初始值（β）

下面的function residuals用来计算r向量（r=[r1,r2...rm]'），residuals(β1,β2...),其中mapslices函数把data矩阵的每一行数据应用括号中的函数

下面的x0其实是参数β

其中for循环下的第一行代码解释：对于训练集里的每一条（行）数据，通过g梯度函数，变成n*1维的向量（这里n表示变量β的个数），而总共有m条数据，因此Jacobian矩阵为m * n矩阵

![1654693014922](https://raw.githubusercontent.com/liang636600/cloudImg/master/images/1654693014922.jpg)

![image-20220608200330035](https://raw.githubusercontent.com/liang636600/cloudImg/master/images/image-20220608200330035.png)

![image-20220608203429310](https://raw.githubusercontent.com/liang636600/cloudImg/master/images/image-20220608203429310.png)

示例

![image-20220608201021690](https://raw.githubusercontent.com/liang636600/cloudImg/master/images/image-20220608201021690.png)

![image-20220608201244785](https://raw.githubusercontent.com/liang636600/cloudImg/master/images/image-20220608201244785.png)