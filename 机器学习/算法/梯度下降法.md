梯度方向是目标函数值增加最快的方向，梯度负方向函数值下降最快

# 1 Batch梯度下降

这里以线性回归算法为例，Batch梯度下降指的是：**遍历整个训练集**计算梯度值，更新一次参数值θ（梯度值如下面蓝色方框内容所示）

![image-20220603161020027](https://raw.githubusercontent.com/liang636600/cloudImg/master/images/image-20220603161020027.png)

## 缺点

当训练的数据集较大的时候（比如上亿条数据），计算一次迭代的梯度值需要遍历整个数据集导致训练较慢

# 2 随机梯度下降（SGD）

**优点：**可以更好处理大型数据集

**核心：**每一条训练数据流进来，更新一次参数值

## 步骤

1. 随机打乱训练集
2. 对训练集中的每一条数据流进来的时候，更新一次θ的值

![image-20220603165724805](https://raw.githubusercontent.com/liang636600/cloudImg/master/images/image-20220603165724805.png)

**效果**：整个过程以随机迂回的方式朝全局最小值前进，如下图粉红色曲线所示，而红色曲线表示的是Batch梯度下降

![image-20220603165958263](https://raw.githubusercontent.com/liang636600/cloudImg/master/images/image-20220603165958263.png)

repeat的次数一般是1~10次

## 如何保证收敛

每1000个迭代时，算出前1000个样本的cost（cost是指一条新的样本流入时，使用之前的模型算一下cost值）的平均值，把这个平均值画出来（平均值的趋势应该是递减的）

![image-20220603172155876](https://raw.githubusercontent.com/liang636600/cloudImg/master/images/image-20220603172155876.png)

画出来的平均值的图可能出现以下的四种情况

* 图一中蓝色线表示每1000个迭代（学习算法收敛），红线表示使用了一个更小的学习速率α
* 图二中蓝线表示每1000个迭代，红线表示每5000个迭代，红线看起来更加平滑，但也存来延迟的问题
* 图三中蓝线表示每1000个迭代（噪声较大），红线表示每5000迭代，粉红线表示每5000迭代（但算法不知什么原因出现没有学习的情况，可以采用调整学习速率或调整特征的方式）
* 图四表示每1000个迭代，cost的平均值上升，这种情况表示发散不收敛，可以采取的措施是使用更小的学习率α

![image-20220603174654820](https://raw.githubusercontent.com/liang636600/cloudImg/master/images/image-20220603174654820.png)

# 3 Mini-Batch梯度下降

 **核心：**每次迭代更新参数会使用b个样本，一般b的值为2~100

![image-20220603171204364](https://raw.githubusercontent.com/liang636600/cloudImg/master/images/image-20220603171204364.png)

**特点：**介于Batch梯度下降算法与随机梯度下降算法之间

# 4 最速下降法

![image-20220604182614877](https://raw.githubusercontent.com/liang636600/cloudImg/master/images/image-20220604182614877.png)

![image-20220604182856585](https://raw.githubusercontent.com/liang636600/cloudImg/master/images/image-20220604182856585.png)

## 二次型函数最速下降法

![image-20220604190225914](https://raw.githubusercontent.com/liang636600/cloudImg/master/images/image-20220604190225914.png)

![image-20220604190654108](https://raw.githubusercontent.com/liang636600/cloudImg/master/images/image-20220604190654108.png)